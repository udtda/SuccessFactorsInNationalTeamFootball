options(scipen=999)
summary(basemodRB)
summary(basemodGB)
# Cross-Validation des fertigen RB Modells
library(caret)
set.seed(100)
X1=cbind(X,y1)
train.control = trainControl(method = "cv", number = 5)
basemodRBcv = train(y1 ~., data = X1, method = "lm",
trControl = train.control)
# Summarize the results
print(basemodRBcv)
# Cross-Validation des fertigen GB Modells
library(caret)
set.seed(100)
X2=cbind(X,y2)
train.control = trainControl(method = "cv", number = 5)
basemodGBcv = train(y2 ~., data = X2, method = "lm",
trControl = train.control)
# Summarize the results
print(basemodGBcv)
# Variablen mit Daten füllen
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
y1=read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
C=1000
n=dim(X)[1]
p=dim(X)[2]
# Erstellen der Tabelle zum Sammeln der ERgebnisse
resulttableLASSOavgGB=cbind(rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]))
rownames(resulttableLASSOavgGB)=colnames(X)
resulttableLASSOavgGB=rbind(c(0,0,0), resulttableLASSOavgGB)
rownames(resulttableLASSOavgGB)[1]=c("Intercept")
colnames(resulttableLASSOavgGB)=c("Share.of.Selections", "Distance.next.variable", "Avg.Coefficient", "Standard.Deviance.Coefficient", "Coefficient.Variation", "Share.same.direction")
# Erstellen einer weiteren Tabelle
valuestableLASSOGB=matrix(ncol=(dim(X)[2]+1), nrow=1000)
colnames(valuestableLASSOGB)[2:(dim(X)[2]+1)]=colnames(X)
colnames(valuestableLASSOGB)[1]=c("Intercept")
valuestableLASSOGB[is.na(valuestableLASSOGB)]=0
valuestableLASSOGB=as.data.frame(valuestableLASSOGB)
options(scipen=999)
library(glmnet)
library(dplyr)
# Variablen mit Daten füllen
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
y1=read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
C=1000
n=dim(X)[1]
p=dim(X)[2]
# Erstellen der Tabelle zum Sammeln der ERgebnisse
resulttableLASSOavgGB=cbind(rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]),rep(0,dim(X)[2]))
rownames(resulttableLASSOavgGB)=colnames(X)
resulttableLASSOavgGB=rbind(c(0,0,0), resulttableLASSOavgGB)
rownames(resulttableLASSOavgGB)[1]=c("Intercept")
colnames(resulttableLASSOavgGB)=c("Share.of.Selections", "Distance.next.variable", "Avg.Coefficient", "Standard.Deviance.Coefficient", "Coefficient.Variation", "Share.same.direction")
# Erstellen einer weiteren Tabelle
valuestableLASSOGB=matrix(ncol=(dim(X)[2]+1), nrow=1000)
colnames(valuestableLASSOGB)[2:(dim(X)[2]+1)]=colnames(X)
colnames(valuestableLASSOGB)[1]=c("Intercept")
valuestableLASSOGB[is.na(valuestableLASSOGB)]=0
valuestableLASSOGB=as.data.frame(valuestableLASSOGB)
options(scipen=999)
# Durchführung des Algorithmus
set.seed(100)
for (i in 1:C){
# Aufteilen der Daten
index=sample(1:n, n*0.5)
X.sub1=X[index,]
X.sub2=X[-index,]
y2.sub1=y2[index]
y2.sub2=y2[-index]
X.sub1=scale(X.sub1)
model=cv.glmnet(as.matrix(X.sub1), y2.sub1, type.measure = "mse")
model.coef=coef(model, s=model$lambda.min)
# Markieren der ausgewählten Koeffizienten in einem Index
print(i)
ind=integer()
for (j in 1:length(model.coef)){
if(model.coef[j]!=0){
ind=c(ind,j)
}
}
if (length(ind)!=1){
# Umgehen der Intercept Spalte
a=cbind(rep(1,dim(X.sub2)[1]), X.sub2)
a=a[,ind]
a=subset(a, select=-c(1))
# Zweites Modell mit nur den im ersten Schritt ausgewählten Variablen, auf der zweiten Hälfte der Daten
mod=lm(data=a, formula = y2.sub2~.)
l=1
for (k in 1:dim(valuestableLASSOGB)[2]){
if(l<=length(ind) && k==ind[l]){
valuestableLASSOGB[i,k]=valuestableLASSOGB[i,k]+as.double(coef(mod)[l])
l=l+1
}
}
}
}
# Befüllen der ersten Spalte der resulttable mit der Anzahl der Selektionen
for (i in 1:dim(resulttableLASSOavgGB)[1]){
resulttableLASSOavgGB[i,1]=sum(valuestableLASSOGB[,i]!=0)
}
# Befüllen der dritten Spalte der resulttable mit den durschnittlichen Koeffizienten
for (i in 1:dim(resulttableLASSOavgGB)[1]){
help=subset(valuestableLASSOGB[,i], valuestableLASSOGB[,i]!=0)
resulttableLASSOavgGB[i,3]=mean(help)
}
# Befüllen der vierten Spalte der resulttable mit der Standardabweichung der Koeffizienten
for (i in 1:dim(resulttableLASSOavgGB)[1]){
help=subset(valuestableLASSOGB[,i], valuestableLASSOGB[,i]!=0)
resulttableLASSOavgGB[i,4]=sd(help)
}
# Befüllen der fünften Spalte der resulttable mit dem Variationskoeffizienten der Koeffizienten
for (i in 1:dim(resulttableLASSOavgGB)[1]){
resulttableLASSOavgGB[i,5]=resulttableLASSOavgGB[i,4]/resulttableLASSOavgGB[i,3]
}
# Befüllen der sechsten Spalte der resulttable mit dem Anteil an Schätzungen mit dem selben Vorzeichen wie der Durchschnittswert
for (i in 1:dim(resulttableLASSOavgGB)[1]){
if(resulttableLASSOavgGB[i,3]>0){
help=subset(valuestableLASSOGB[,i], valuestableLASSOGB[,i]>0)
resulttableLASSOavgGB[i,6]=length(help)/resulttableLASSOavgGB[i,1]
}
if(resulttableLASSOavgGB[i,3]<0){
help=subset(valuestableLASSOGB[,i], valuestableLASSOGB[,i]<0)
resulttableLASSOavgGB[i,6]=length(help)/resulttableLASSOavgGB[i,1]
}
}
# Teilen der Anzahl der Selektionen durch C
C=resulttableLASSOavgGB["Intercept",1]
resulttableLASSOavgGB=as.data.frame(resulttableLASSOavgGB)
for(i in 1:dim(resulttableLASSOavgGB)[1]){
if(resulttableLASSOavgGB[i,1]!=0){
resulttableLASSOavgGB[i,1]=round(resulttableLASSOavgGB[i,1]/C, digits = 3)
}
}
# Sortieren der Tabelle und bestimmen des ABstands zur nächsten Klasse
resulttableLASSOavgGB=resulttableLASSOavgGB%>%arrange(Share.of.Selections)
for (i in 1:(dim(resulttableLASSOavgGB)[1]-1)){
resulttableLASSOavgGB[i,2]=resulttableLASSOavgGB[i+1,1]-resulttableLASSOavgGB[i,1]
}
# Runden
resulttableLASSOavgGB[,4]=round(resulttableLASSOavgGB[,4], digits=3)
resulttableLASSOavgGB[,5]=round(resulttableLASSOavgGB[,5], digits=3)
resulttableLASSOavgGB[,6]=round(resulttableLASSOavgGB[,6], digits=3)
print(resulttableLASSOavgGB)
View(resulttableLASSOavgGB)
# Fitten mithilfe dieses Modells
X1=X[,c("shotAccuracy","DistanceCoveredComp","MarketValueCompFact", "SaveRate", "Tackles.Attempted", "Tackle.rate","Errors",  "Dribbles", "Passes...Length...Long")]
colnames(X1)=c("Shot accuracy", "Distance covered difference","log(Market value ratio)", "Save rate", "Tackles attempted", "Tackle rate", "Errors", "Dribbles","Long passes")
# Cross-Validation des fertigen Modells
library(caret)
set.seed(100)
X1=subset(X1, select = -c(1))
X1=cbind(X1,y2)
train.control = trainControl(method = "cv", number = 5)
model = train(y2 ~., data = X1, method = "lm",
trControl = train.control)
# Summarize the results
print(model)
# Fitten mithilfe dieses Modells
X1=X[,c("Shot accuracy", "Distance covered difference","log(Market value ratio)", "Save rate", "Tackles attempted", "Tackle rate", "Errors", "Dribbles","Long passes")]
# Fitten mithilfe dieses Modells
X1=X[,c("shotAccuracy","DistanceCoveredComp","MarketValueCompFact", "SaveRate", "Tackles.Attempted", "Tackle.rate","Errors",  "Dribbles", "Passes...Length...Long")]
colnames(X1)=c("Shot accuracy", "Distance covered difference","log(Market value ratio)", "Save rate", "Tackles attempted", "Tackle rate", "Errors", "Dribbles","Long passes")
# Cross-Validation des fertigen Modells
library(caret)
set.seed(100)
X1=cbind(X1,y2)
train.control = trainControl(method = "cv", number = 5)
model = train(y2 ~., data = X1, method = "lm",
trControl = train.control)
# Summarize the results
print(model)
# plot Selection Share
plot(resulttableLASSOavgGB$Share.of.Selections, type ="s", ylab="Share of selections")
rect(xleft=0, xright = 11, ybottom=0, ytop = 0.03, col= rgb(0,1,0,alpha=0.3), border = rgb(0,1,0,alpha=0.3))
rect(xleft=11, xright = 41, ybottom=0.0, ytop = 0.03, col= rgb(1,0,0,alpha=0.6), border = rgb(1,0,0,alpha=0.6))
resulttableLASSOavgGB=resulttableLASSOavgGB%>%arrange(desc(Share.of.Selections))
plot(resulttableLASSOavgGB$Share.of.Selections, type ="s", ylab="Share of selections")
rect(xleft=0, xright = 11, ybottom=0, ytop = 0.03, col= rgb(0,1,0,alpha=0.3), border = rgb(0,1,0,alpha=0.3))
rect(xleft=11, xright = 41, ybottom=0.0, ytop = 0.03, col= rgb(1,0,0,alpha=0.6), border = rgb(1,0,0,alpha=0.6))
# Cross-Validation des fertigen Modells
library(caret)
set.seed(100)
X1=X[,c("shotAccuracy", "DistanceCoveredComp","MarketValueCompFact","Passes...Pass.Type...Cross", "Tackles.Attempted",  "SaveRate", "Passes...Length...Long", "Dribbles", "Clearances")]
X1=cbind(X1,y1)
train.control = trainControl(method = "cv", number = 5)
model = train(y1 ~., data = X1, method = "lm",
trControl = train.control)
# Summarize the results
print(model)
library(glmnet)
library(nnet)
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
y1=read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
varnames=c("Shots", "Passes", "Dribbles", "Tackles attempted", "Interceptions", "Clearances", "Blocks",
"Offsides", "Fouls", "Aerial duels", "Loss of possession", "Errors","Claims", "Punches", "Shots from open play",
"Shots from fastbreak", "Shots from set pieces", "Penalties", "Crosses", "Freekicks", "Corners", "Through balls",
"Throw ins", "Key passes", "Long passes", "Chipped passes", "Headed passes", "Passes into defensive third",
"Passes into final third", "Average age", "Ball possession", "Pass rate", "Tackle rate", "Home advantage", "Travel distance", "wHA", "Shot accuracy", "Save rate",
"log(Market value ratio)", "Distance covered difference")
colnames(X)=varnames
model=multinom(data=X, formula = y1~.)
summary(model)
library(xtable)
xtable(t(coef(model)), digits=5)
## Cross-Validation des fertigen Modells
library(caret)
set.seed(100)
X3=cbind(X,y1)
train.control = trainControl(method = "cv", number = 5)
model = train(y1 ~., data = X3, method = "multinom", trControl = train.control)
print(model)
set.seed(100)
X3=cbind(X,y1)
train.control = trainControl(method = "cv", number = 5)
modelCV = train(y1 ~., data = X3, method = "multinom", trControl = train.control)
y1=factor(read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D)
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
y1=factor(read.csv("Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D)
varnames=c("Shots", "Passes", "Dribbles", "Tackles attempted", "Interceptions", "Clearances", "Blocks",
"Offsides", "Fouls", "Aerial duels", "Loss of possession", "Errors","Claims", "Punches", "Shots from open play",
"Shots from fastbreak", "Shots from set pieces", "Penalties", "Crosses", "Freekicks", "Corners", "Through balls",
"Throw ins", "Key passes", "Long passes", "Chipped passes", "Headed passes", "Passes into defensive third",
"Passes into final third", "Average age", "Ball possession", "Pass rate", "Tackle rate", "Home advantage", "Travel distance", "wHA", "Shot accuracy", "Save rate",
"log(Market value ratio)", "Distance covered difference")
colnames(X)=varnames
model=multinom(data=X, formula = y1~.)
summary(model)
## Cross-Validation des fertigen Modells
library(caret)
set.seed(100)
X3=cbind(X,y1)
train.control = trainControl(method = "cv", number = 5)
modelCV = train(y1 ~., data = X3, method = "multinom", trControl = train.control)
print(modelCV)
##########################
##Step 2
finalset=c("MarketValueCompFact","shotAccuracy", "DistanceCoveredComp","SaveRate","Dribbles", "Tackles.Attempted","Passes...Pass.Type...Cross", "Passes...Length...Long", "Clearances")
X1=X[,finalset]
View(X)
View(X)
##########################
##Step 2
finalset=c("log(Market value ratio)","Shot accuracy", "Distance covered difference","Save rate","Dribbles", "Tackles attempted","Crosses", "Long passes", "Clearances")
X1=X[,finalset]
crlasso.final1=vglm(data=b, y1~., family=cumulative(parallel=TRUE, reverse = TRUE))
library(glmnet)
library(glmnetcr)
library(ordinalNet)
library(nnet)
library(VGAM)
library(MASS)
library(dplyr)
brant::brant(polr(y1~X1, Hess = TRUE))
brant::brant(polr(y1~as.matrix(X1), Hess = TRUE))
#########################
#CV
set.seed(123)
X2=cbind(X1, y1)
samp=sample(seq(1,102), 102, replace = F)
a=split(samp, 1:5)
accuracy.res=double()
for(i in 1:5){
Xt=NULL
k=rep(1:5)[-i]
for(j in 1:length(k)){
Xt=rbind(Xt, X2[a[[j]],])
}
mod=vglm(data=Xt, formula=y1~., family=cumulative(parallel=TRUE, reverse = TRUE))
summary(mod)
ab=X2[a[[i]],]
ab=ab[,-which(colnames(ab)=="y1")]
pred=predictvglm(mod, ab, type = "response")
pred1=integer()
for(k in 1:dim(pred)[1]){
pred1=append(pred1,(as.integer(names(which.max(pred[k,])))))
}
actual=as.integer(X2[a[[i]],]$y1)
actual=actual-rep(2, length(actual))
res=data.frame(cbind(pred1, actual))
tab=table(res$pred1, res$actual)
print(tab)
accuracy=(tab[1,1]+tab[2,2]+tab[3,3])/(dim(res)[1])
print(accuracy)
accuracy.res=append(accuracy.res, accuracy)
}
mean(accuracy.res)
resulttableLASSOavgMLOG2=resulttableLASSOavgMLOG2%>%arrange(desc(Share.of.Selections))
########### Baseline model
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
########### Baseline model
X=read.csv("WebScraping/Data_clean.csv", header=TRUE, row.names = 1)
data=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)
library(highcharter)
library(dplyr)
data=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)
############## Exchanging Ball possession values due to wrong allocation
for (i in 1:(nrow(data)-1)){
if(i%%2==1){
helper=data$Ball.Posession[i+1]
data[i+1,"Ball.Posession"]=data$Ball.Posession[i]
data[i,"Ball.Posession"]=helper
}
}
############# Adding additional variables
wHA=c()
shotAccuracy=c()
SaveRate=c()
MarketValueCompFact=c()
DistanceCoveredComp=c()
HomeAdvantage=c(-1,1,0,0,1,-1,-1,1,1,-1,0,0,1,-1,1,-1,0,0,1,-1,1,-1,-1,1,-1,1,0,0,1,-1,0,0,1,-1,1,-1,0,0,0,0,1,-1,1,-1,-1,1,1,-1,1,-1,0,0,-1,1,0,0,-1,1,0,0,-1,1,-1,1,0,0,-1,1,1,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,-1,0,0,0,0,0,0,0,0,0,0,0,0,1,-1,-1,1)
for (i in 1:dim(data)[1]){
helper=HomeAdvantage[i]*data$Spectators[i]
wHA=append(wHA, helper)
}
for (i in 1:dim(data)[1]){
helper=round((data$Shots...Results...Shots.on.Target[i]/data$Shots[i])*100, digits = 2)
shotAccuracy=append(shotAccuracy, helper)
}
for (i in 1:dim(data)[1]){
if (i%%2 == 1){
helper=round((data$Saves[i]/data$Shots...Results...Shots.on.Target[i+1]*100), digits = 2)
SaveRate=append(SaveRate, helper)
}
if (i%%2 == 0){
helper=round((data$Saves[i]/data$Shots...Results...Shots.on.Target[i-1]*100), digits = 2)
SaveRate=append(SaveRate, helper)
}
}
indexna=which(is.na(SaveRate))
SaveRate[indexna]=0
indexinf=which(is.finite(SaveRate)==FALSE)
SaveRate[indexinf]=100
for (i in 1:dim(data)[1]){
if (i%%2 == 1){
helper=round(data$Market.Value[i]/data$Market.Value[i+1], digits = 2)
MarketValueCompFact=append(MarketValueCompFact, helper)
}
if (i%%2 == 0){
helper=round(data$Market.Value[i]/data$Market.Value[i-1], digits = 2)
MarketValueCompFact=append(MarketValueCompFact, helper)
}
}
for (i in 1:dim(data)[1]){
if (i%%2 == 1){
helper=round(data$Distance.covered[i]-data$Distance.covered[i+1], digits = 2)
DistanceCoveredComp=append(DistanceCoveredComp, helper)
}
if (i%%2 == 0){
helper=round(data$Distance.covered[i]-data$Distance.covered[i-1], digits = 2)
DistanceCoveredComp=append(DistanceCoveredComp, helper)
}
}
data=cbind(data, HomeAdvantage, wHA, shotAccuracy, SaveRate, MarketValueCompFact, DistanceCoveredComp)
data$MarketValueCompFact=log(data$MarketValueCompFact)
data=cbind(rownames(data), data)
data$SaveRate=round(data$SaveRate, digits = 0)
colnames(data)[1]=c("Match")
write.csv(data, "Data_complete_full.csv", row.names = FALSE)
data=data[,-1]
############# Pre-processing
# Removing "Clearances - off the line" (all zeros), 'Market Value' and 'Distance covered', and all Result columns
data_red=subset(data, select = -c(59,69,74,75,76,77))
#Testing for perfect correlation
for (i in 1:(dim(data_red)[2]-1)){
for (j in (i+1):dim(data_red)[2]){
test=cor(data_red[,i], data_red[,j])
if (test==1 || test==-1){
print(colnames(data_red)[i])
print(colnames(data_red)[j])
print(test)
print(" ")
}
}
}
#Deleting "Clearances - Outcome - total" and "Shots - Situation - Own Goal" due to perfect correlation
data_red=subset(data_red, select = -c(58, 30))
#Testing for almost perfect correlation
for (i in 1:(dim(data_red)[2]-1)){
for (j in (i+1):dim(data_red)[2]){
test=cor(data_red[,i], data_red[,j])
if (test>0.95 || test<(-0.95)){
print(colnames(data_red)[i])
print(colnames(data_red)[j])
print(test)
print(' ')
}
}
}
# Deleting "Touches" as well as "Passes - Length - Short", "Passes - Height - Ground", "Passes - Body Part - Feet", "Passes - Target Zone - Mid Third" and all "Passes - Direction"
data_red=subset(data_red, select = -c(11, 41,43,45, 46:49, 51))
#Testing for correlation > 0.9
for (i in 1:(dim(data_red)[2]-1)){
for (j in (i+1):dim(data_red)[2]){
test=cor(data_red[,i], data_red[,j])
if (test>0.9 || test<(-0.9)){
print(colnames(data_red)[i])
print(colnames(data_red)[j])
print(test)
print(' ')
}
}
}
#Checking VIFs for each remaining Variable
vifs=as.data.frame(matrix(ncol=2, nrow = dim(data_red)[2]))
for (i in 1:dim(data_red)[2]){
helpset=subset(data_red, select = -c(i))
helpmodel=lm(data=helpset, formula = data_red[,i] ~.)
helprsquared=summary(helpmodel)$r.squared
if (helprsquared != 1){
vifhelp=1/(1-helprsquared)
} else {
vifhelp=99999
}
vifs[i,1]=colnames(data_red)[i]
vifs[i,2]=round(vifhelp, digits = 2)
}
vifs
# Reducing Data by removing detailed components such as "Shots - Results" (relevant information is represented in shotAccuracy),
# "Shots - Zones" ,"Shots - Body parts" (not relevant in theory) and any
# detailed stats for Dribbles, Tackles, Clearances, Blocks, Loss of Possession and Errors
data_red=subset(data_red, select = -c(16:24, 29:32, 44:55))
#Checking VIFs for each remaining Variable
vifs=matrix(ncol=2, nrow = dim(data_red)[2])
vifs=as.data.frame(vifs)
for (i in 1:dim(data_red)[2]){
helpset=subset(data_red, select = -c(i))
helpmodel=lm(data=helpset, formula = data_red[,i] ~.)
helprsquared=summary(helpmodel)$r.squared
if (helprsquared != 1){
vifhelp=1/(1-helprsquared)
} else {
vifhelp=99999
}
vifs[i,1]=colnames(data_red)[i]
vifs[i,2]=round(vifhelp, digits = 2)
}
vifs
# Deleting Saves and spectators (correlation to result is obviously 0)
data_red=data_red[,-c(13,33)]
# Writing final data set into csv file
data_clean=cbind(rownames(data_red), data_red)
colnames(data_clean)[1]=c("Match")
write.csv(data_clean, "Data_clean.csv", row.names = FALSE)
########### Baseline model
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
########### Baseline model
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
y1=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
y1=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
# Variablen mit Daten füllen
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
y1=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("WebScraping/Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
getwd()
setwd('..')
getwd()
setwd('..')
getwd()
setwd('./WebScraping/2020')
getwd()
setwd('..')
getwd()
setwd('..')
getwd()
data=read.csv("WebScraping/2020/Data_complete.csv", header=TRUE, row.names = 1)
setwd('./Analyse/2020')
getwd()
getwd()
setwd('..')
setwd('..')
data=read.csv("WebScraping/2020/Data_complete.csv", header=TRUE, row.names = 1)
setwd('./Analyse/2020')
############## Exchanging Ball possession values due to wrong allocation
for (i in 1:(nrow(data)-1)){
if(i%%2==1){
helper=data$Ball.Posession[i+1]
data[i+1,"Ball.Posession"]=data$Ball.Posession[i]
data[i,"Ball.Posession"]=helper
}
}
getwd()
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
setwd('..')
setwd('..')
y1=read.csv("WebScraping/2020/Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("WebScraping/2020/Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
setwd('./Analyse/2020')
# Brant test
finalset=c("log(Market value ratio)","Shot accuracy", "Distance covered difference","Save rate","Dribbles", "Tackles attempted","Crosses", "Long passes", "Clearances")
X1=X[,finalset]
X=read.csv("Data_clean.csv", header=TRUE, row.names = 1)
setwd('..')
setwd('..')
y1=read.csv("WebScraping/2020/Data_complete.csv", header=TRUE, row.names = 1)$Result.W.L.D
y2=read.csv("WebScraping/2020/Data_complete.csv", header=TRUE, row.names = 1)$Result.GoalDiff
setwd('./Analyse/2020')
# Brant test
finalset=c("log(Market value ratio)","Shot accuracy", "Distance covered difference","Save rate","Dribbles", "Tackles attempted","Crosses", "Long passes", "Clearances")
X1=X[,finalset]
View(X)
# Brant test
finalset=c("MarketValueCompFact","shotAccuracy", "DistanceCoveredComp","SaveRate","Dribbles", "Tackles.Attempted","Passes...Pass.Type...Cross","Passes...Length...Long", "Clearances")
X1=X[,finalset]
Source("BrantTest.R")
source("BrantTest.R")
brant_cr(finalset,FALSE)
